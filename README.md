# ETL-скрипт для загрузки CSV в PostgreSQL

## Описание проекта

Скрипт автоматически загружает все `.csv`-файлы из указанной папки в соответствующие таблицы схемы `ds` в базе данных **PostgreSQL**.  
Каждый шаг процесса логируется в отдельную таблицу — `logs.etl_log`.

---

## Стек технологий

-  **Python** (`pandas`, `psycopg2`, `SQLAlchemy`)
-  **PostgreSQL**
-  **CSV**

---

##  Структура проекта

├── csv_files/ # Папка с входными CSV-файлами
├── main_etl.py # Основной ETL-скрипт
├── sql.sql # SQL-скрипт для создания таблиц и схем
├── docker-compose.yaml # Docker-конфигурация для PostgreSQL
├── presentation1-1.mp4 # Видеопрезентация проекта
├── .gitignore # Файл исключений Git
└── logs.etl_log # Таблица логирования (в схеме logs)


---

##  Как работает скрипт

1.  Подключение к базе данных (основной и логов)
2.  Определение имени таблицы по имени CSV-файла
3.  Чтение CSV с поддержкой нескольких кодировок (`utf-8`, `ISO-8859-1`)
4.  Автоматическое определение столбцов с датами и типов данных
5.  Проверка наличия уникальных ключей таблицы
6.  Пакетная вставка данных с `ON CONFLICT DO UPDATE`
7.  Логирование каждого этапа в `logs.etl_log`

---
Все подходящие CSV-файлы из папки csv_files/ будут загружены автоматически.

## Таблица логирования

Логи записываются в таблицу logs.etl_log со следующими полями:

- log_time — время записи

- severity — уровень важности (INFO, WARNING, ERROR)

- message — сообщение

Это позволяет отслеживать ход выполнения, ошибки и предупреждения на каждом этапе процесса.

## Демонстрация

Видеодемонстрация проекта: presentation1-1.mp4

